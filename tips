1.对真实图片进行归一化，与生成图片分布一样，也就是[-1,1].
2.随机噪声使用高斯分布，不要使用均匀分布，也就是在代码中使用torch.randn，而不是torch.rand
3.初始化权重很有必要，详细见model.py中的weight_init函数
4.在训练时，在鉴别器中产生的noise，生成器也要用这个noise进行参数，这点很重要。鉴别器随机产生noise，生成器也随机产生noise，训练得会很不好。
5.在训练过程中，很有可能鉴别器的loss等于0（鉴别器太强了，起初我试过减小鉴别器的学习率，但还是会有这个情况，我猜想原因是在某一个batch中，鉴别器恰好将随机噪声产生的图片和真实图片完全区分开，loss为0），导致生成器崩溃（梯度弥散），所以最好按多少个epoch保存模型，然后在导入模型再训练。

相比GAN的优点/DCGAN能改进GAN训练稳定的原因主要有：
 使用步长卷积代替上采样层，卷积在提取图像特征上具有很好的作用，并且使用卷积代替全连接层。
 生成器G和判别器D中几乎每一层都使用batchnorm层，将特征层的输出归一化到一起，加速了训练，提升了训练的稳定性。（生成器的最后一层和判别器的第一层不加batchnorm）
 在判别器中使用leakrelu激活函数，而不是RELU，防止梯度稀疏，生成器中仍然采用relu，但是输出层采用tanh
 使用adam优化器训练，并且学习率最好是0.0002。
